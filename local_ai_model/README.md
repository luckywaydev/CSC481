# Local AI Model - Faster Whisper

โปรเจคนี้ใช้ Faster Whisper สำหรับการแปลงเสียงเป็นข้อความ (Speech-to-Text) ที่มีประสิทธิภาพสูง

## การติดตั้ง

1. ติดตั้ง dependencies:
```bash
pip install -r requirements.txt
```

2. ตรวจสอบให้แน่ใจว่ามี NVIDIA GPU และได้ติดตั้ง:
- CUDA 12
- cuBLAS
- cuDNN 9

## การใช้งาน

1. วาง file เสียงที่ต้องการแปลงในโฟลเดอร์นี้ (รองรับ .mp3, .wav, etc.)

2. รันโปรแกรม:
```bash
python transcribe.py
```

## คุณสมบัติ

- รองรับหลายภาษารวมถึงภาษาไทย
- ความแม่นยำสูง
- ประมวลผลเร็วกว่า OpenAI Whisper ต้นฉบับถึง 4 เท่า
- รองรับการทำงานบน CPU และ GPU
- มี VAD filter สำหรับกรองช่วงเงียบ
- สามารถระบุเวลาของแต่ละคำ (word-level timestamps)

## ข้อกำหนดของระบบ

- Python 3.9 หรือใหม่กว่า
- GPU NVIDIA ที่รองรับ CUDA (แนะนำ)
- RAM อย่างน้อย 8GB
- พื้นที่ว่างอย่างน้อย 10GB สำหรับโมเดล

## หมายเหตุ

- โมเดลจะถูกดาวน์โหลดอัตโนมัติเมื่อรันครั้งแรก
- สามารถปรับแต่งพารามิเตอร์ต่างๆ ได้ในไฟล์ transcribe.py